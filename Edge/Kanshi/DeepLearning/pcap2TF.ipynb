{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Deep Learning in Secutity \n",
    "\n",
    "    ## PCAP file is used form a Data set  \"train_ds\"\n",
    "    ## train_ds is used to  train DL TF  Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install  tensorflow_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow_io as tfio \n",
    "import tensorflow_io as tfio\n",
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an IODataset from a pcap file  \n",
    "#first_file = tfio.IODataset.from_pcap('randpkt-2020-04-02-31746.pcap')\n",
    "#second_file = tfio.IODataset.from_pcap(['randpkt-2020-09-06-16170.pcap'])\n",
    "first_file = tfio.IODataset.from_pcap('jk1.pcap')\n",
    "second_file = tfio.IODataset.from_pcap(['jkmachine.pcap'])\n",
    "\n",
    "# Concatenate the Read Files\n",
    "feature = first_file.concatenate(second_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for pcap \n",
    "packet_timestamp_list = []\n",
    "packet_data_list = []\n",
    "packet_dataNum_list = []\n",
    "\n",
    "# some dummy labels\n",
    "labels = []\n",
    "packets_total = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # print(packet_data.numpy(),' ')\n",
    "    # print(x,' ')\n",
    "    # print(packet_timestamp.numpy())\n",
    "    #if packets_total == 0:\n",
    "    #    assert np.isclose(packet_timestamp.numpy()[0], 1084443427.311224, rtol=1e-15)  # we know this is the correct value in the test pcap file\n",
    "    #    assert (len(packet_data.numpy()[0]) == 62)  # we know this is the correct packet data buffer length in the test pcap file\n",
    "    \n",
    "    # print(packets_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "90\n",
      "66\n",
      "54\n",
      "54\n",
      "42\n",
      "1399\n",
      "702\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for vfeature in feature:\n",
    "    (packet_timestamp, packet_data) = vfeature   \n",
    "    pData = packet_data.numpy()\n",
    "    kk= len(pData)\n",
    "    print(kk)\n",
    "    pktdata = [pData[i:i + 4] for i in range(0, kk, 4)]\n",
    "    pktLength = len(pktdata)\n",
    "    for j in range(0,pktLength):\n",
    "        locData = pktdata[j]\n",
    "        packet_timestamp_list.append(packet_timestamp.numpy())\n",
    "        x = int.from_bytes(locData, \"big\")\n",
    "        packet_dataNum_list.append(x)\n",
    "        labels.append(0)\n",
    "        \n",
    "    packets_total += 1\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ConcatenateDataset shapes: ((), ()), types: (tf.float64, tf.string)>\n",
      "9\n",
      "643\n",
      "643\n"
     ]
    }
   ],
   "source": [
    "print(feature)\n",
    "print(packets_total)\n",
    "print(len( packet_timestamp_list))\n",
    "print(len( packet_dataNum_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do the preprocessing of packet_data here\n",
    "\n",
    "# Add labels to the training data\n",
    "# Preprocess the packet_data to convert string to meaningful value and use here\n",
    "\n",
    "#train_ds = tf.data.Dataset.from_tensor_slices(((packet_timestamp_list,packet_dataNum_list), labels))\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(((packet_dataNum_list), labels))\n",
    "# Set the batch size\n",
    "train_ds = train_ds.shuffle(5000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None,), (None,)), types: (tf.int64, tf.int32)>\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(train_ds)\n",
    "print(len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PROGRAM WILL RUN SUCCESSFULLY TILL HERE. \n",
    "###  TO USE IN THE MODEL DO THE PREPROCESSING OF PACKET DATA AS EXPLAINED ### \n",
    "# Have defined some simple model\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(100),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.9965e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 7.8002e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 6.7264e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 5.2731e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 4.4536e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 3.7715e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 3.2756e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.8254e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27e826d828>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: jj_model/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save(\"jj_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ref\n",
    "1. https://www.kdnuggets.com/2020/01/python-string-processing-primer.html  String Utility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291355863412692747297030401\n",
      "291355863412692747297030401\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "xx= b'\\xf8\\xda\\x0cH\\xb9\\xd1x2\\x1bA\\xdf\\xfb\\x08\\x00E\\x00\\x004}\\x1a\\x00\\x00<\\x06\\xf1\\xf0\"\\x95+q\\xc0\\xa8\\x01\\x0b\\x01\\xbb\\xd9\\x8e\\xfd\\xe8$\\xe4\\xa4W\\xa7\\xcd\\x80\\x11\\x01!\\\\J\\x00\\x00\\x01\\x01\\x08\\n\\xa88\\x93\\x11#\\xf9`\\x18'\n",
    "# declaring byte value\n",
    "byte_val = b'\\xF1\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01'\n",
    "\n",
    "# converting to int\n",
    "# byteorder is big where MSB is at start\n",
    "int_val = int.from_bytes(byte_val, \"big\")\n",
    "# printing int equivalent\n",
    "print(int_val)\n",
    "\n",
    "x = int.from_bytes(byte_val, \"big\")\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'\\x00\\x00', b'\\x00\\x00', b'\\x00\\x00']\n"
     ]
    }
   ],
   "source": [
    "data = b'\\x00\\x00\\x00\\x00\\x00\\x00'\n",
    " \n",
    "info = [data[i:i + 2] for i in range(0, len(data), 2)]\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x00'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "int_val = int.from_bytes(info[0], \"big\")\n",
    "print(int_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
